{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf","metadata":{"execution":{"iopub.status.busy":"2024-10-08T19:53:13.612461Z","iopub.execute_input":"2024-10-08T19:53:13.612808Z","iopub.status.idle":"2024-10-08T19:56:33.212012Z","shell.execute_reply.started":"2024-10-08T19:53:13.612771Z","shell.execute_reply":"2024-10-08T19:56:33.211043Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2024-10-08 19:53:14--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\nResolving huggingface.co (huggingface.co)... 18.172.134.88, 18.172.134.24, 18.172.134.4, ...\nConnecting to huggingface.co (huggingface.co)|18.172.134.88|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1728676394&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODY3NjM5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=m8%7E7WAJYCO4NbYgOB9%7ETn9p8h2WzOnaQbd6j02PYonOrkHvqc91BUnRnjyLchZ1izWGjKgMj2Kfz7jdN8aJmW7BYepktnTykC70eRs8BBcMmqS0Yd1LNrKMhtbioVcD3GqRzN0Js15VddChkYcrXSB2Xep7ZOD8lSJO3JGtN-ViHiZ64dWADRsAxao8tAWVd-BsEO9lSEU1R2lACuNIaLOSjEFfGqlOR6lZ3rkoTlXAbs1KcG%7EAgfJr2-Z7-N8vU1Mvym7SjTEffzuCegO975Vdi6bZ8JEeyCIf5lAnyszyO%7EA-4stupXKt3rEev3Oce%7E8s0zr9YY1sTFqJj9PbQVA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2024-10-08 19:53:14--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8''Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1728676394&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODY3NjM5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=m8~7WAJYCO4NbYgOB9~Tn9p8h2WzOnaQbd6j02PYonOrkHvqc91BUnRnjyLchZ1izWGjKgMj2Kfz7jdN8aJmW7BYepktnTykC70eRs8BBcMmqS0Yd1LNrKMhtbioVcD3GqRzN0Js15VddChkYcrXSB2Xep7ZOD8lSJO3JGtN-ViHiZ64dWADRsAxao8tAWVd-BsEO9lSEU1R2lACuNIaLOSjEFfGqlOR6lZ3rkoTlXAbs1KcG~AgfJr2-Z7-N8vU1Mvym7SjTEffzuCegO975Vdi6bZ8JEeyCIf5lAnyszyO~A-4stupXKt3rEev3Oce~8s0zr9YY1sTFqJj9PbQVA__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.225.120, 18.160.225.13, 18.160.225.98, ...\nConnecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.225.120|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7643295904 (7.1G) [binary/octet-stream]\nSaving to: 'Phi-3-mini-4k-instruct-fp16.gguf'\n\nPhi-3-mini-4k-instr 100%[===================>]   7.12G  29.1MB/s    in 3m 18s  \n\n2024-10-08 19:56:33 (36.8 MB/s) - 'Phi-3-mini-4k-instruct-fp16.gguf' saved [7643295904/7643295904]\n\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"from langchain_community.llms import LlamaCpp\n\nllm = LlamaCpp(\n    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n    n_gpu_layers=50,\n    max_tokens=500,\n    n_ctx=2048,\n    seed=42,\n    verbose=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:02.220495Z","iopub.execute_input":"2024-10-08T20:26:02.220950Z","iopub.status.idle":"2024-10-08T20:26:03.374495Z","shell.execute_reply.started":"2024-10-08T20:26:02.220909Z","shell.execute_reply":"2024-10-08T20:26:03.373468Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from langchain import PromptTemplate\n\ntemplate = \"\"\"<s><|user|>\n{input_prompt}<|end|>\n<|assistant|>\"\"\"\n\nprompt = PromptTemplate(template = template, input_variables = [\"input_prompt\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:32:19.848141Z","iopub.execute_input":"2024-10-08T20:32:19.848922Z","iopub.status.idle":"2024-10-08T20:32:19.854079Z","shell.execute_reply.started":"2024-10-08T20:32:19.848874Z","shell.execute_reply":"2024-10-08T20:32:19.853042Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"basic_chain = prompt | llm","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:32:21.124565Z","iopub.execute_input":"2024-10-08T20:32:21.125197Z","iopub.status.idle":"2024-10-08T20:32:21.129639Z","shell.execute_reply.started":"2024-10-08T20:32:21.125158Z","shell.execute_reply":"2024-10-08T20:32:21.128584Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"basic_chain.invoke(\n    {\n        \"input_prompt\":\"Hi! My name is Maarten. What is 1 + 1?\"\n    })","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:06:57.660569Z","iopub.execute_input":"2024-10-08T20:06:57.661474Z","iopub.status.idle":"2024-10-08T20:07:05.487292Z","shell.execute_reply.started":"2024-10-08T20:06:57.661428Z","shell.execute_reply":"2024-10-08T20:07:05.486290Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"' Hello Maarten! The answer to 1 + 1 is 2.'"},"metadata":{}}]},{"cell_type":"code","source":"llm.invoke(\"Hi! My name is Maarten. What is 1 + 1?\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:07:26.712638Z","iopub.execute_input":"2024-10-08T20:07:26.713099Z","iopub.status.idle":"2024-10-08T20:07:28.046771Z","shell.execute_reply.started":"2024-10-08T20:07:26.713058Z","shell.execute_reply":"2024-10-08T20:07:28.045626Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"''"},"metadata":{}}]},{"cell_type":"code","source":"from langchain import LLMChain\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"<s><|user|>\nCreate a title for a story about {summary}. Only return the title.<|end|>\n<|assistant|>\"\"\"\n\ntitle_prompt = PromptTemplate(template = template, input_variables = [\"summary\"])\ntitle = LLMChain(llm = llm, prompt=title_prompt, output_key = \"title\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:22.342057Z","iopub.execute_input":"2024-10-08T20:26:22.342945Z","iopub.status.idle":"2024-10-08T20:26:22.348387Z","shell.execute_reply.started":"2024-10-08T20:26:22.342902Z","shell.execute_reply":"2024-10-08T20:26:22.347440Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"<s><|user|>\nDescribe the main character of a story about {summary} with the title {title}. Use only two sentences.<|end|>\n<|assistant|>\"\"\"\n\ncharacter_prompt = PromptTemplate(template = template, input_variables=['summary', 'title'])\ncharacter = LLMChain(llm = llm, prompt = character_prompt, output_key = \"character\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:33.152709Z","iopub.execute_input":"2024-10-08T20:26:33.153382Z","iopub.status.idle":"2024-10-08T20:26:33.158630Z","shell.execute_reply.started":"2024-10-08T20:26:33.153340Z","shell.execute_reply":"2024-10-08T20:26:33.157530Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"template =\"\"\"<s><|user|>\nCreate a story about {summary} with the title {title}. The main character is: {character}. Only return the story and it cannot be longer than one paragraph\n<|assistant|>\"\"\"\nstory_prompt = PromptTemplate(template=template, input_variables=[\"summary\",\"title\",\"character\"])\nstory = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:34.308605Z","iopub.execute_input":"2024-10-08T20:26:34.309779Z","iopub.status.idle":"2024-10-08T20:26:34.315204Z","shell.execute_reply.started":"2024-10-08T20:26:34.309717Z","shell.execute_reply":"2024-10-08T20:26:34.314175Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"llm_chain = title | character | story","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:35.393012Z","iopub.execute_input":"2024-10-08T20:26:35.393860Z","iopub.status.idle":"2024-10-08T20:26:35.398128Z","shell.execute_reply.started":"2024-10-08T20:26:35.393813Z","shell.execute_reply":"2024-10-08T20:26:35.397150Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"basic_chain.invoke({\"input_prompt\":\"Hi my name is Rupak. What is an apple?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:33:00.948958Z","iopub.execute_input":"2024-10-08T20:33:00.949423Z","iopub.status.idle":"2024-10-08T20:33:46.996503Z","shell.execute_reply.started":"2024-10-08T20:33:00.949383Z","shell.execute_reply":"2024-10-08T20:33:46.995648Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"\" Hello Rupak! An apple is a type of fruit that grows on trees in the Malus genus. It's one of the most widely cultivated and consumed fruits around the world, known for its sweet taste when ripe but also for having various varieties with different flavors (some more tart). Apples are rich in fiber, vitamin C, and various antioxidants. They come in many colors such as red, green, and yellow, and their crisp texture makes them popular in a variety of dishes and snacks like salads, pies, and sauces.\""},"metadata":{}}]},{"cell_type":"code","source":"basic_chain.invoke({\"input_prompt\":\"Hey What's my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:34:11.072386Z","iopub.execute_input":"2024-10-08T20:34:11.073269Z","iopub.status.idle":"2024-10-08T20:34:26.607318Z","shell.execute_reply.started":"2024-10-08T20:34:11.073229Z","shell.execute_reply":"2024-10-08T20:34:26.606281Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"\" I'm unable to determine your name without more context. If you need help remembering a name or if it was mentioned previously in our conversation, please provide additional details so I can assist you better.\""},"metadata":{}}]},{"cell_type":"code","source":"template = \"\"\"<s><|user|>Current conversation:{chat_history}\n\n{input_prompt}<|end|>\n<|assistant|>\"\"\"\n\nprompt = PromptTemplate(\ntemplate = template,\ninput_variables = [\"input_prompt\", \"chat_history\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:36:39.097834Z","iopub.execute_input":"2024-10-08T20:36:39.098714Z","iopub.status.idle":"2024-10-08T20:36:39.103323Z","shell.execute_reply.started":"2024-10-08T20:36:39.098668Z","shell.execute_reply":"2024-10-08T20:36:39.102300Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\n\nllm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:38:36.996626Z","iopub.execute_input":"2024-10-08T20:38:36.997049Z","iopub.status.idle":"2024-10-08T20:38:37.039777Z","shell.execute_reply.started":"2024-10-08T20:38:36.997002Z","shell.execute_reply":"2024-10-08T20:38:37.038854Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3546962061.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n","output_type":"stream"}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\": \"Hi! My name is Rupal. What is 1 + 1?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:38:50.148055Z","iopub.execute_input":"2024-10-08T20:38:50.148735Z","iopub.status.idle":"2024-10-08T20:39:06.304282Z","shell.execute_reply.started":"2024-10-08T20:38:50.148692Z","shell.execute_reply":"2024-10-08T20:39:06.303275Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'Hi! My name is Rupal. What is 1 + 1?',\n 'chat_history': '',\n 'text': ' The sum of 1 + 1 is 2.\\n\\nExplanation: This simple arithmetic problem has a fixed answer, which in mathematics, adding one to another one results in two.'}"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"Hi! What is my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:40:18.870325Z","iopub.execute_input":"2024-10-08T20:40:18.870958Z","iopub.status.idle":"2024-10-08T20:40:38.156315Z","shell.execute_reply.started":"2024-10-08T20:40:18.870917Z","shell.execute_reply":"2024-10-08T20:40:38.155145Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'Hi! What is my name?',\n 'chat_history': 'Human: Hi! My name is Rupal. What is 1 + 1?\\nAI:  The sum of 1 + 1 is 2.\\n\\nExplanation: This simple arithmetic problem has a fixed answer, which in mathematics, adding one to another one results in two.',\n 'text': ' Hi Rupal! Your name is mentioned at the beginning of this conversation. You said, \"My name is Rupal.\"\\n\\nSo your name is Rupal.'}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain.memory import ConversationBufferWindowMemory\n# Retain only the last 2 conversations in memory\nmemory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n\nllm_chain = LLMChain(\nprompt = prompt,\nllm=llm,\nmemory=memory)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:41:57.804528Z","iopub.execute_input":"2024-10-08T20:41:57.805490Z","iopub.status.idle":"2024-10-08T20:41:57.817724Z","shell.execute_reply.started":"2024-10-08T20:41:57.805442Z","shell.execute_reply":"2024-10-08T20:41:57.816629Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1039188648.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n","output_type":"stream"}]},{"cell_type":"code","source":"llm_chain.predict(input_prompt=\"Hi! My name is Maarten and I am 33 years old. What is 1 + 1?\")\nllm_chain.predict(input_prompt=\"What is 3 + 3?\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:42:23.437796Z","iopub.execute_input":"2024-10-08T20:42:23.438466Z","iopub.status.idle":"2024-10-08T20:42:46.173884Z","shell.execute_reply.started":"2024-10-08T20:42:23.438416Z","shell.execute_reply":"2024-10-08T20:42:46.172881Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"' 6\\nAnswer: 6'"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"What is my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:43:10.538354Z","iopub.execute_input":"2024-10-08T20:43:10.539268Z","iopub.status.idle":"2024-10-08T20:43:17.256039Z","shell.execute_reply.started":"2024-10-08T20:43:10.539226Z","shell.execute_reply":"2024-10-08T20:43:17.255040Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What is my name?',\n 'chat_history': \"Human: Hi! My name is Maarten and I am 33 years old. What is 1 + 1?\\nAI:  Hi Maarten! It's great to meet you. 1 + 1 equals 2. How can I assist you further?\\nAnswer: 2\\nHuman: What is 3 + 3?\\nAI:  6\\nAnswer: 6\",\n 'text': ' Your name is Maarten.\\nAnswer: Maarten'}"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"What is my age?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:43:51.176620Z","iopub.execute_input":"2024-10-08T20:43:51.177111Z","iopub.status.idle":"2024-10-08T20:44:20.043025Z","shell.execute_reply.started":"2024-10-08T20:43:51.177060Z","shell.execute_reply":"2024-10-08T20:44:20.042058Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What is my age?',\n 'chat_history': 'Human: What is 3 + 3?\\nAI:  6\\nAnswer: 6\\nHuman: What is my name?\\nAI:  Your name is Maarten.\\nAnswer: Maarten',\n 'text': \" As an AI, I don't have the ability to know personal information about individuals unless it has been shared with me in the course of our conversation. If you provide your age at any point during our interaction, I can assist or remind you accordingly. However, for privacy reasons, I cannot access such data without your consent.\"}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}