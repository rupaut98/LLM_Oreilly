{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:32:58.838790Z","iopub.execute_input":"2024-10-09T18:32:58.839196Z","iopub.status.idle":"2024-10-09T18:33:36.741084Z","shell.execute_reply.started":"2024-10-09T18:32:58.839156Z","shell.execute_reply":"2024-10-09T18:33:36.739834Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"--2024-10-09 18:32:59--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\nResolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.124, 18.172.134.88, ...\nConnecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1728757980&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODc1Nzk4MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gbJjZWS-SAOAsa7vsIDAqWUlCfGIJmRpZ1ri4eHsJaBtuJ-vZ2L-0um9IULDgBnTnWPBQ6imJwTENrU558BJhswwy0QIjvEcjJo5uisjndQ49nz9WRyG1WdiF%7EZu62hAsLSr4HmZk5lS1ZP-LumSSZdHw6umojrjlk4GHGlvFcAhSyRFBZdIsIrBV9XuzLsVeqBOvbuqmwSYhqCW80BV09y9%7EYQcMYLDo7sxxfBl0vSohqlIBZflsGZ8N65YSLGn8TBgmzc-DSjTGt90GSE3ekV4HWW5Tg9rAC2NsAKNxpMPNm67nXGbxh2Twoday6zqoHjwGW7hn65cbYkK6ODjJQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2024-10-09 18:33:00--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8''Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1728757980&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODc1Nzk4MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gbJjZWS-SAOAsa7vsIDAqWUlCfGIJmRpZ1ri4eHsJaBtuJ-vZ2L-0um9IULDgBnTnWPBQ6imJwTENrU558BJhswwy0QIjvEcjJo5uisjndQ49nz9WRyG1WdiF~Zu62hAsLSr4HmZk5lS1ZP-LumSSZdHw6umojrjlk4GHGlvFcAhSyRFBZdIsIrBV9XuzLsVeqBOvbuqmwSYhqCW80BV09y9~YQcMYLDo7sxxfBl0vSohqlIBZflsGZ8N65YSLGn8TBgmzc-DSjTGt90GSE3ekV4HWW5Tg9rAC2NsAKNxpMPNm67nXGbxh2Twoday6zqoHjwGW7hn65cbYkK6ODjJQ__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.225.13, 18.160.225.120, 18.160.225.72, ...\nConnecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.225.13|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7643295904 (7.1G) [binary/octet-stream]\nSaving to: 'Phi-3-mini-4k-instruct-fp16.gguf'\n\nPhi-3-mini-4k-instr 100%[===================>]   7.12G   211MB/s    in 36s     \n\n2024-10-09 18:33:36 (205 MB/s) - 'Phi-3-mini-4k-instruct-fp16.gguf' saved [7643295904/7643295904]\n\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install langchain-community\nfrom langchain_community.llms import LlamaCpp\n\nllm = LlamaCpp(\n    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n    n_gpu_layers=50,\n    max_tokens=500,\n    n_ctx=2048,\n    seed=42,\n    verbose=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:40:05.133325Z","iopub.execute_input":"2024-10-09T18:40:05.133862Z","iopub.status.idle":"2024-10-09T18:40:18.507877Z","shell.execute_reply.started":"2024-10-09T18:40:05.133821Z","shell.execute_reply":"2024-10-09T18:40:18.506933Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (0.3.2)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: langchain<0.4.0,>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.3)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.10)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.132)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.5.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\nRequirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (2.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain import PromptTemplate\n\ntemplate = \"\"\"<s><|user|>\n{input_prompt}<|end|>\n<|assistant|>\"\"\"\n\nprompt = PromptTemplate(template = template, input_variables = [\"input_prompt\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:32:19.848141Z","iopub.execute_input":"2024-10-08T20:32:19.848922Z","iopub.status.idle":"2024-10-08T20:32:19.854079Z","shell.execute_reply.started":"2024-10-08T20:32:19.848874Z","shell.execute_reply":"2024-10-08T20:32:19.853042Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"basic_chain = prompt | llm","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:32:21.124565Z","iopub.execute_input":"2024-10-08T20:32:21.125197Z","iopub.status.idle":"2024-10-08T20:32:21.129639Z","shell.execute_reply.started":"2024-10-08T20:32:21.125158Z","shell.execute_reply":"2024-10-08T20:32:21.128584Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"basic_chain.invoke(\n    {\n        \"input_prompt\":\"Hi! My name is Maarten. What is 1 + 1?\"\n    })","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:06:57.660569Z","iopub.execute_input":"2024-10-08T20:06:57.661474Z","iopub.status.idle":"2024-10-08T20:07:05.487292Z","shell.execute_reply.started":"2024-10-08T20:06:57.661428Z","shell.execute_reply":"2024-10-08T20:07:05.486290Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"' Hello Maarten! The answer to 1 + 1 is 2.'"},"metadata":{}}]},{"cell_type":"code","source":"llm.invoke(\"Hi! My name is Maarten. What is 1 + 1?\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:07:26.712638Z","iopub.execute_input":"2024-10-08T20:07:26.713099Z","iopub.status.idle":"2024-10-08T20:07:28.046771Z","shell.execute_reply.started":"2024-10-08T20:07:26.713058Z","shell.execute_reply":"2024-10-08T20:07:28.045626Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"''"},"metadata":{}}]},{"cell_type":"code","source":"from langchain import LLMChain\nfrom langchain import PromptTemplate\n\ntemplate = \"\"\"<s><|user|>\nCreate a title for a story about {summary}. Only return the title.<|end|>\n<|assistant|>\"\"\"\n\ntitle_prompt = PromptTemplate(template = template, input_variables = [\"summary\"])\ntitle = LLMChain(llm = llm, prompt=title_prompt, output_key = \"title\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:22.342057Z","iopub.execute_input":"2024-10-08T20:26:22.342945Z","iopub.status.idle":"2024-10-08T20:26:22.348387Z","shell.execute_reply.started":"2024-10-08T20:26:22.342902Z","shell.execute_reply":"2024-10-08T20:26:22.347440Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"template = \"\"\"<s><|user|>\nDescribe the main character of a story about {summary} with the title {title}. Use only two sentences.<|end|>\n<|assistant|>\"\"\"\n\ncharacter_prompt = PromptTemplate(template = template, input_variables=['summary', 'title'])\ncharacter = LLMChain(llm = llm, prompt = character_prompt, output_key = \"character\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:33.152709Z","iopub.execute_input":"2024-10-08T20:26:33.153382Z","iopub.status.idle":"2024-10-08T20:26:33.158630Z","shell.execute_reply.started":"2024-10-08T20:26:33.153340Z","shell.execute_reply":"2024-10-08T20:26:33.157530Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"template =\"\"\"<s><|user|>\nCreate a story about {summary} with the title {title}. The main character is: {character}. Only return the story and it cannot be longer than one paragraph\n<|assistant|>\"\"\"\nstory_prompt = PromptTemplate(template=template, input_variables=[\"summary\",\"title\",\"character\"])\nstory = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:34.308605Z","iopub.execute_input":"2024-10-08T20:26:34.309779Z","iopub.status.idle":"2024-10-08T20:26:34.315204Z","shell.execute_reply.started":"2024-10-08T20:26:34.309717Z","shell.execute_reply":"2024-10-08T20:26:34.314175Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"llm_chain = title | character | story","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:26:35.393012Z","iopub.execute_input":"2024-10-08T20:26:35.393860Z","iopub.status.idle":"2024-10-08T20:26:35.398128Z","shell.execute_reply.started":"2024-10-08T20:26:35.393813Z","shell.execute_reply":"2024-10-08T20:26:35.397150Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"basic_chain.invoke({\"input_prompt\":\"Hi my name is Rupak. What is an apple?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:33:00.948958Z","iopub.execute_input":"2024-10-08T20:33:00.949423Z","iopub.status.idle":"2024-10-08T20:33:46.996503Z","shell.execute_reply.started":"2024-10-08T20:33:00.949383Z","shell.execute_reply":"2024-10-08T20:33:46.995648Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"\" Hello Rupak! An apple is a type of fruit that grows on trees in the Malus genus. It's one of the most widely cultivated and consumed fruits around the world, known for its sweet taste when ripe but also for having various varieties with different flavors (some more tart). Apples are rich in fiber, vitamin C, and various antioxidants. They come in many colors such as red, green, and yellow, and their crisp texture makes them popular in a variety of dishes and snacks like salads, pies, and sauces.\""},"metadata":{}}]},{"cell_type":"code","source":"basic_chain.invoke({\"input_prompt\":\"Hey What's my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:34:11.072386Z","iopub.execute_input":"2024-10-08T20:34:11.073269Z","iopub.status.idle":"2024-10-08T20:34:26.607318Z","shell.execute_reply.started":"2024-10-08T20:34:11.073229Z","shell.execute_reply":"2024-10-08T20:34:26.606281Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"\" I'm unable to determine your name without more context. If you need help remembering a name or if it was mentioned previously in our conversation, please provide additional details so I can assist you better.\""},"metadata":{}}]},{"cell_type":"code","source":"template = \"\"\"<s><|user|>Current conversation:{chat_history}\n\n{input_prompt}<|end|>\n<|assistant|>\"\"\"\n\nprompt = PromptTemplate(\ntemplate = template,\ninput_variables = [\"input_prompt\", \"chat_history\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:46:28.039420Z","iopub.execute_input":"2024-10-09T18:46:28.040161Z","iopub.status.idle":"2024-10-09T18:46:28.044795Z","shell.execute_reply.started":"2024-10-09T18:46:28.040122Z","shell.execute_reply":"2024-10-09T18:46:28.043801Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\n\nllm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:38:36.996626Z","iopub.execute_input":"2024-10-08T20:38:36.997049Z","iopub.status.idle":"2024-10-08T20:38:37.039777Z","shell.execute_reply.started":"2024-10-08T20:38:36.997002Z","shell.execute_reply":"2024-10-08T20:38:37.038854Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3546962061.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n","output_type":"stream"}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\": \"Hi! My name is Rupal. What is 1 + 1?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:38:50.148055Z","iopub.execute_input":"2024-10-08T20:38:50.148735Z","iopub.status.idle":"2024-10-08T20:39:06.304282Z","shell.execute_reply.started":"2024-10-08T20:38:50.148692Z","shell.execute_reply":"2024-10-08T20:39:06.303275Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'Hi! My name is Rupal. What is 1 + 1?',\n 'chat_history': '',\n 'text': ' The sum of 1 + 1 is 2.\\n\\nExplanation: This simple arithmetic problem has a fixed answer, which in mathematics, adding one to another one results in two.'}"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"Hi! What is my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:40:18.870325Z","iopub.execute_input":"2024-10-08T20:40:18.870958Z","iopub.status.idle":"2024-10-08T20:40:38.156315Z","shell.execute_reply.started":"2024-10-08T20:40:18.870917Z","shell.execute_reply":"2024-10-08T20:40:38.155145Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'Hi! What is my name?',\n 'chat_history': 'Human: Hi! My name is Rupal. What is 1 + 1?\\nAI:  The sum of 1 + 1 is 2.\\n\\nExplanation: This simple arithmetic problem has a fixed answer, which in mathematics, adding one to another one results in two.',\n 'text': ' Hi Rupal! Your name is mentioned at the beginning of this conversation. You said, \"My name is Rupal.\"\\n\\nSo your name is Rupal.'}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain.memory import ConversationBufferWindowMemory\n# Retain only the last 2 conversations in memory\nmemory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n\nllm_chain = LLMChain(\nprompt = prompt,\nllm=llm,\nmemory=memory)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:41:57.804528Z","iopub.execute_input":"2024-10-08T20:41:57.805490Z","iopub.status.idle":"2024-10-08T20:41:57.817724Z","shell.execute_reply.started":"2024-10-08T20:41:57.805442Z","shell.execute_reply":"2024-10-08T20:41:57.816629Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1039188648.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n","output_type":"stream"}]},{"cell_type":"code","source":"llm_chain.predict(input_prompt=\"Hi! My name is Maarten and I am 33 years old. What is 1 + 1?\")\nllm_chain.predict(input_prompt=\"What is 3 + 3?\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:42:23.437796Z","iopub.execute_input":"2024-10-08T20:42:23.438466Z","iopub.status.idle":"2024-10-08T20:42:46.173884Z","shell.execute_reply.started":"2024-10-08T20:42:23.438416Z","shell.execute_reply":"2024-10-08T20:42:46.172881Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"' 6\\nAnswer: 6'"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"What is my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:43:10.538354Z","iopub.execute_input":"2024-10-08T20:43:10.539268Z","iopub.status.idle":"2024-10-08T20:43:17.256039Z","shell.execute_reply.started":"2024-10-08T20:43:10.539226Z","shell.execute_reply":"2024-10-08T20:43:17.255040Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What is my name?',\n 'chat_history': \"Human: Hi! My name is Maarten and I am 33 years old. What is 1 + 1?\\nAI:  Hi Maarten! It's great to meet you. 1 + 1 equals 2. How can I assist you further?\\nAnswer: 2\\nHuman: What is 3 + 3?\\nAI:  6\\nAnswer: 6\",\n 'text': ' Your name is Maarten.\\nAnswer: Maarten'}"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\":\"What is my age?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-08T20:43:51.176620Z","iopub.execute_input":"2024-10-08T20:43:51.177111Z","iopub.status.idle":"2024-10-08T20:44:20.043025Z","shell.execute_reply.started":"2024-10-08T20:43:51.177060Z","shell.execute_reply":"2024-10-08T20:44:20.042058Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What is my age?',\n 'chat_history': 'Human: What is 3 + 3?\\nAI:  6\\nAnswer: 6\\nHuman: What is my name?\\nAI:  Your name is Maarten.\\nAnswer: Maarten',\n 'text': \" As an AI, I don't have the ability to know personal information about individuals unless it has been shared with me in the course of our conversation. If you provide your age at any point during our interaction, I can assist or remind you accordingly. However, for privacy reasons, I cannot access such data without your consent.\"}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain import PromptTemplate\nsummary_prompt_template = \"\"\"<s><|user|>Summarize the conversations and update with the new lines.\n\nCurrent Summary:\n{summary}\n\nnew lines of conversation:\n{new_lines}\n\nNew summary:<|end|>\n<|assistant|>\"\"\"\n\nsummary_prompt = PromptTemplate(\ninput_variables = [\"summary\", 'new_lines'],\ntemplate = summary_prompt_template,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:38:29.795348Z","iopub.execute_input":"2024-10-09T18:38:29.795749Z","iopub.status.idle":"2024-10-09T18:38:29.983322Z","shell.execute_reply.started":"2024-10-09T18:38:29.795712Z","shell.execute_reply":"2024-10-09T18:38:29.982521Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from langchain.memory import ConversationSummaryMemory\nfrom langchain import LLMChain\n\nmemory = ConversationSummaryMemory(\nllm = llm,\nmemory_key = \"chat_history\",\nprompt = summary_prompt)\n\nllm_chain = LLMChain(\nprompt = prompt,\nllm=llm,\nmemory = memory)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:46:30.604157Z","iopub.execute_input":"2024-10-09T18:46:30.604558Z","iopub.status.idle":"2024-10-09T18:46:30.618735Z","shell.execute_reply.started":"2024-10-09T18:46:30.604520Z","shell.execute_reply":"2024-10-09T18:46:30.617673Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/588819442.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n  llm_chain = LLMChain(\n","output_type":"stream"}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\"})\nllm_chain.invoke({\"input_prompt\": \"What is my name?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:46:46.464973Z","iopub.execute_input":"2024-10-09T18:46:46.465697Z","iopub.status.idle":"2024-10-09T18:49:08.760128Z","shell.execute_reply.started":"2024-10-09T18:46:46.465656Z","shell.execute_reply":"2024-10-09T18:49:08.759039Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What is my name?',\n 'chat_history': ' Maarten introduces himself and asks a simple arithmetic question, \"What is 1 + 1?\" The AI responds with the answer, 2, along with a step-by-step explanation that addition of two units results in two. The updated summary includes this detailed breakdown:\\n\\nMaarten introduced himself as \\'My name is Maarten\\', asks for the result of 1 + 1, and receives a comprehensive arithmetic explanation confirming it equals 2.',\n 'text': ' Your name is Maarten.'}"},"metadata":{}}]},{"cell_type":"code","source":"llm_chain.invoke({\"input_prompt\": \"What was the first question I asked?\"})","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:53:31.806497Z","iopub.execute_input":"2024-10-09T18:53:31.806919Z","iopub.status.idle":"2024-10-09T18:54:33.320489Z","shell.execute_reply.started":"2024-10-09T18:53:31.806883Z","shell.execute_reply":"2024-10-09T18:54:33.319395Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/llama_cpp/llama.py:1238: RuntimeWarning: Detected duplicate leading \"<s>\" in prompt, this will likely reduce response quality, consider removing it...\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'input_prompt': 'What was the first question I asked?',\n 'chat_history': \" Maarten identifies himself as 'My name is Maarten', inquires about the result of 1 + 1, and receives an arithmetic explanation confirming it equals 2. He also learns that his name is Maarten from the AI's response to a different question regarding his name.\",\n 'text': ' The first question you asked Maarten was, \"What is the result of 1 + 1?\"'}"},"metadata":{}}]},{"cell_type":"code","source":"memory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2024-10-09T18:55:30.769493Z","iopub.execute_input":"2024-10-09T18:55:30.770418Z","iopub.status.idle":"2024-10-09T18:55:30.776658Z","shell.execute_reply.started":"2024-10-09T18:55:30.770377Z","shell.execute_reply":"2024-10-09T18:55:30.775585Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'chat_history': \" Maarten introduces himself as 'My name is Maarten' and asks about the result of 1 + 1, to which he receives an arithmetic explanation confirming it equals 2. He also confirms his name with the AI upon a separate question. When asked what his first question was by the human, the AI reminds him that the initial inquiry involved finding the sum of 1 + 1.\"}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}